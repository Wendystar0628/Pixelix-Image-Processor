# é‡æ„æ³¨æ„äº‹é¡¹æ–‡æ¡£

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜äº†åœ¨è¿›è¡Œå¤§è§„æ¨¡ä»£ç ç»“æ„é‡æ„æ—¶éœ€è¦ç‰¹åˆ«æ³¨æ„çš„å…³é”®é—®é¢˜å’Œé£é™©ç‚¹ã€‚è¿™äº›æ³¨æ„äº‹é¡¹åŸºäºå®é™…é‡æ„ç»éªŒæ€»ç»“ï¼Œæ—¨åœ¨å¸®åŠ©å¼€å‘è€…é¿å…å¸¸è§é™·é˜±ï¼Œç¡®ä¿é‡æ„è¿‡ç¨‹çš„é¡ºåˆ©è¿›è¡Œã€‚

## å…³é”®é£é™©ç‚¹å’Œé¢„é˜²æªæ–½

### 1. ä¾èµ–æ³¨å…¥å’Œåº”ç”¨ä¸Šä¸‹æ–‡å¤±æ•ˆ ğŸš¨

**é£é™©ç­‰çº§**: æé«˜ - å¯èƒ½å¯¼è‡´åº”ç”¨æ— æ³•å¯åŠ¨

#### é—®é¢˜æè¿°
AppContextæ˜¯åº”ç”¨çš„"å¿ƒè„"ï¼Œè´Ÿè´£æŒ‰æ­£ç¡®é¡ºåºå®ä¾‹åŒ–æ‰€æœ‰æ ¸å¿ƒæœåŠ¡å’Œç®¡ç†å™¨ã€‚é‡æ„åï¼Œå‡ ä¹æ¯ä¸€æ¡importè¯­å¥éƒ½ä¼šå¤±æ•ˆï¼Œå¯¼è‡´æ•´ä¸ªä¾èµ–æ³¨å…¥ä½“ç³»å´©æºƒã€‚

#### å…·ä½“è¡¨ç°
```python
# é‡æ„å‰çš„AppContextå¯èƒ½åŒ…å«è¿™æ ·çš„ä»£ç 
from app.core.integration.extensible_processor import ExtensibleImageProcessor
from app.core.managers.batch_job_manager import BatchJobManager
from app.handlers.batch_processing.batch_processing_handler import BatchProcessingHandler

# é‡æ„åè¿™äº›å¯¼å…¥å…¨éƒ¨å¤±æ•ˆï¼Œå¯¼è‡´åº”ç”¨æ— æ³•å¯åŠ¨
```

#### é¢„é˜²å’Œè§£å†³æªæ–½

1. **ä¼˜å…ˆä¿®å¤ç­–ç•¥**
   - AppContextåº”è¯¥æ˜¯é‡æ„åç¬¬ä¸€ä¸ªè¦ä¿®å¤çš„æ–‡ä»¶
   - åœ¨å®Œæˆæ–‡ä»¶ç§»åŠ¨åï¼Œç«‹å³æ›´æ–°æ‰€æœ‰importè¯­å¥

2. **ç³»ç»Ÿæ€§æ›´æ–°æ–¹æ³•**
   ```python
   # åˆ›å»ºå¯¼å…¥æ˜ å°„è¡¨
   IMPORT_MAPPING = {
       'app.core.integration.extensible_processor': 'app.core.processing.image_processor',
       'app.core.managers.batch_job_manager': 'app.features.batch_processing.managers.job_manager',
       'app.handlers.batch_processing.batch_processing_handler': 'app.features.batch_processing.handler'
   }
   
   # ä½¿ç”¨è„šæœ¬æ‰¹é‡æ›´æ–°å¯¼å…¥è¯­å¥
   def update_imports_in_file(file_path, mapping):
       with open(file_path, 'r') as f:
           content = f.read()
       
       for old_import, new_import in mapping.items():
           content = content.replace(old_import, new_import)
       
       with open(file_path, 'w') as f:
           f.write(content)
   ```

3. **å®ä¾‹åŒ–é¡ºåºéªŒè¯**
   ```python
   # ç¡®ä¿ä¾èµ–å…³ç³»æ­£ç¡®
   class AppContext:
       def __init__(self):
           # 1. é¦–å…ˆåˆå§‹åŒ–æ ¸å¿ƒæœåŠ¡ï¼ˆæ— ä¾èµ–ï¼‰
           self.resource_manager = ResourceManager()
           self.image_processor = ExtensibleImageProcessor()
           
           # 2. ç„¶ååˆå§‹åŒ–ä¾èµ–æ ¸å¿ƒæœåŠ¡çš„ç»„ä»¶
           self.task_coordinator = TaskCoordinator(self.resource_manager)
           
           # 3. æœ€ååˆå§‹åŒ–åŠŸèƒ½æ¨¡å—ï¼ˆä¾èµ–æ ¸å¿ƒæœåŠ¡ï¼‰
           self.batch_handler = BatchProcessingHandler(
               image_processor=self.image_processor,
               resource_manager=self.resource_manager
           )
   ```

### 2. Qtä¿¡å·æ§½è¿æ¥æ–­è£‚ âš ï¸

**é£é™©ç­‰çº§**: é«˜ - å¯¼è‡´UIåŠŸèƒ½å¤±æ•ˆ

#### é—®é¢˜æè¿°
Qtçš„ä¿¡å·æ§½æœºåˆ¶ä¾èµ–äºå¯¹è±¡å®ä¾‹çš„æ­£ç¡®åˆ›å»ºã€‚å¦‚æœAppContextæ— æ³•åˆ›å»ºå¤„ç†å™¨å¯¹è±¡ï¼Œæˆ–è€…ä¿¡å·å®šä¹‰ä¸­çš„è‡ªå®šä¹‰ç±»å‹å¯¼å…¥å¤±æ•ˆï¼Œä¼šå¯¼è‡´UIæŒ‰é’®ç‚¹å‡»æ— å“åº”ã€‚

#### å…·ä½“è¡¨ç°
```python
# UIç»„ä»¶ä¸­çš„ä¿¡å·å®šä¹‰
class BatchProgressDialog(QDialog):
    # å¦‚æœBatchJobçš„å¯¼å…¥è·¯å¾„é”™è¯¯ï¼Œè¿™ä¸ªä¿¡å·å®šä¹‰ä¼šå¤±è´¥
    job_finished = pyqtSignal(BatchJob)  # å¯èƒ½å¯¼è‡´è¿è¡Œæ—¶é”™è¯¯
    
    def __init__(self):
        super().__init__()
        # å¦‚æœself.handleræ˜¯Noneï¼Œè¿™è¡Œä»£ç ä¼šå´©æºƒ
        self.button.clicked.connect(self.handler.start_processing)
```

#### é¢„é˜²å’Œè§£å†³æªæ–½

1. **ä¿¡å·å®šä¹‰æ£€æŸ¥**
   ```python
   # æ£€æŸ¥æ‰€æœ‰pyqtSignalå®šä¹‰ä¸­çš„è‡ªå®šä¹‰ç±»å‹
   from app.features.batch_processing.models import BatchJob, JobStatus
   
   class BatchProgressDialog(QDialog):
       job_finished = pyqtSignal(BatchJob)
       status_changed = pyqtSignal(JobStatus)
   ```

2. **è¿æ¥å®‰å…¨æ€§éªŒè¯**
   ```python
   def setup_connections(self):
       # æ·»åŠ å®‰å…¨æ£€æŸ¥
       if hasattr(self, 'handler') and self.handler is not None:
           self.button.clicked.connect(self.handler.start_processing)
       else:
           print("è­¦å‘Šï¼šå¤„ç†å™¨æœªæ­£ç¡®åˆå§‹åŒ–ï¼Œä¿¡å·æ§½è¿æ¥å¤±è´¥")
   ```

3. **UIæ–‡ä»¶é‡æ–°ç¼–è¯‘**
   ```bash
   # å¦‚æœä½¿ç”¨.uiæ–‡ä»¶ï¼Œéœ€è¦é‡æ–°ç¼–è¯‘
   pyuic5 -x dialog.ui -o dialog.py
   ```

### 3. æ•°æ®æŒä¹…åŒ–ä¸ååºåˆ—åŒ–å¤±è´¥ ğŸ’¾

**é£é™©ç­‰çº§**: ä¸­é«˜ - ç”¨æˆ·æ•°æ®ä¸¢å¤±é£é™©

#### é—®é¢˜æè¿°
ä½¿ç”¨pickleä¿å­˜çš„å¯¹è±¡åŒ…å«å®Œæ•´çš„æ¨¡å—è·¯å¾„ã€‚é‡æ„åï¼Œæ—§çš„è·¯å¾„ä¸å­˜åœ¨ï¼Œå¯¼è‡´æ— æ³•åŠ è½½ç”¨æˆ·ä¹‹å‰ä¿å­˜çš„é¡¹ç›®æ–‡ä»¶ã€‚

#### å…·ä½“è¡¨ç°
```python
# é‡æ„å‰ä¿å­˜çš„pickleæ–‡ä»¶åŒ…å«è¿™æ ·çš„è·¯å¾„
# 'app.core.models.batch_models.BatchJob'

# é‡æ„åè¯¥è·¯å¾„ä¸å­˜åœ¨ï¼ŒåŠ è½½æ—¶ä¼šæŠ›å‡º
# ModuleNotFoundError: No module named 'app.core.models.batch_models'
```

#### é¢„é˜²å’Œè§£å†³æªæ–½

1. **é¿å…ç›´æ¥åºåˆ—åŒ–å¯¹è±¡**
   ```python
   # ä¸æ¨èï¼šç›´æ¥pickleå¯¹è±¡
   import pickle
   with open('project.pkl', 'wb') as f:
       pickle.dump(batch_job, f)
   
   # æ¨èï¼šåºåˆ—åŒ–æ•°æ®å­—å…¸
   import json
   job_data = {
       'id': batch_job.id,
       'name': batch_job.name,
       'status': batch_job.status.value,
       'input_files': batch_job.input_files
   }
   with open('project.json', 'w') as f:
       json.dump(job_data, f)
   ```

2. **åˆ›å»ºæ•°æ®è¿ç§»è„šæœ¬**
   ```python
   def migrate_old_pickle_files():
       """è¿ç§»æ—§çš„pickleæ–‡ä»¶åˆ°æ–°æ ¼å¼"""
       import sys
       import os
       
       # ä¸´æ—¶æ·»åŠ æ—§è·¯å¾„åˆ°sys.pathä»¥æ”¯æŒæ—§çš„å¯¼å…¥
       old_paths = ['backup_app']  # å¤‡ä»½çš„æ—§ä»£ç è·¯å¾„
       for path in old_paths:
           if path not in sys.path:
               sys.path.insert(0, path)
       
       try:
           # åŠ è½½æ—§çš„pickleæ–‡ä»¶
           with open('old_project.pkl', 'rb') as f:
               old_data = pickle.load(f)
           
           # è½¬æ¢ä¸ºæ–°çš„æ•°æ®æ ¼å¼
           new_data = convert_to_new_format(old_data)
           
           # ä¿å­˜ä¸ºJSONæ ¼å¼
           with open('project.json', 'w') as f:
               json.dump(new_data, f)
               
       finally:
           # æ¸…ç†ä¸´æ—¶è·¯å¾„
           for path in old_paths:
               if path in sys.path:
                   sys.path.remove(path)
   ```

3. **ç‰ˆæœ¬å…¼å®¹æ€§å¤„ç†**
   ```python
   def load_project_file(file_path):
       """æ™ºèƒ½åŠ è½½é¡¹ç›®æ–‡ä»¶ï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
       if file_path.endswith('.json'):
           return load_json_project(file_path)
       elif file_path.endswith('.pkl'):
           try:
               return load_pickle_project(file_path)
           except (ImportError, ModuleNotFoundError):
               print("æ£€æµ‹åˆ°æ—§æ ¼å¼æ–‡ä»¶ï¼Œæ­£åœ¨å°è¯•è¿ç§»...")
               return migrate_and_load(file_path)
   ```

### 4. å¾ªç¯å¯¼å…¥é—®é¢˜ ğŸ”„

**é£é™©ç­‰çº§**: ä¸­ - å¯¼è‡´æ¨¡å—åŠ è½½å¤±è´¥

#### é—®é¢˜æè¿°
é‡æ„è¿‡ç¨‹ä¸­å®¹æ˜“æ— æ„é—´åˆ›å»ºå¾ªç¯å¯¼å…¥ï¼Œç‰¹åˆ«æ˜¯å½“æ ¸å¿ƒæœåŠ¡éœ€è¦å¼•ç”¨åŠŸèƒ½æ¨¡å—çš„æŸäº›ç»„ä»¶æ—¶ã€‚åœ¨åˆ†æå¯¼å‡ºåŠŸèƒ½é›†æˆæ—¶ï¼Œè¿™ä¸ªé—®é¢˜å°¤å…¶çªå‡ºã€‚

#### å…·ä½“è¡¨ç°
```python
# app/core/resources/manager.py
from app.features.batch_processing.models import BatchJob  # é”™è¯¯ï¼šæ ¸å¿ƒæœåŠ¡ä¾èµ–åŠŸèƒ½æ¨¡å—

# app/features/batch_processing/handler.py  
from app.core.resources.manager import ResourceManager  # å½¢æˆå¾ªç¯ä¾èµ–

# åˆ†æå¯¼å‡ºåŠŸèƒ½çš„æ½œåœ¨å¾ªç¯å¯¼å…¥
# app/core/services/analysis_export_service.py
from app.features.batch_processing.models import AnalysisExportConfig  # é”™è¯¯

# app/features/batch_processing/analysis/services/analysis_export_adapter.py
from app.core.services.analysis_export_service import AnalysisExportService  # å½¢æˆå¾ªç¯
```

#### é¢„é˜²å’Œè§£å†³æªæ–½

1. **éµå®ˆä¾èµ–æ–¹å‘åŸåˆ™**
   ```
   åŠŸèƒ½å±‚ (Features) â†’ æ ¸å¿ƒæœåŠ¡å±‚ (Core) âœ“
   æ ¸å¿ƒæœåŠ¡å±‚ (Core) â†’ åŠŸèƒ½å±‚ (Features) âœ—
   ```

2. **ä½¿ç”¨ä¾èµ–å€’ç½®åŸåˆ™**
   ```python
   # åœ¨æ ¸å¿ƒæœåŠ¡ä¸­å®šä¹‰æ¥å£
   # app/core/resources/interfaces.py
   from abc import ABC, abstractmethod
   
   class JobInfo(ABC):
       @abstractmethod
       def get_resource_requirements(self): pass
   
   # app/core/services/interfaces.py
   class AnalysisExportConfig(ABC):
       @abstractmethod
       def get_output_directory(self): pass
       
       @abstractmethod
       def get_analysis_types(self): pass
   
   # åœ¨åŠŸèƒ½æ¨¡å—ä¸­å®ç°æ¥å£
   # app/features/batch_processing/models.py
   from app.core.resources.interfaces import JobInfo
   from app.core.services.interfaces import AnalysisExportConfig as BaseAnalysisExportConfig
   
   class BatchJob(JobInfo):
       def get_resource_requirements(self):
           return {'memory': '1GB', 'cpu': 2}
   
   class AnalysisExportConfig(BaseAnalysisExportConfig):
       def __init__(self, output_dir, analysis_types):
           self.output_dir = output_dir
           self.analysis_types = analysis_types
       
       def get_output_directory(self):
           return self.output_dir
       
       def get_analysis_types(self):
           return self.analysis_types
   ```

3. **ä½¿ç”¨ä¾èµ–æ³¨å…¥**
   ```python
   # æ ¸å¿ƒæœåŠ¡ä¸ç›´æ¥å¯¼å…¥åŠŸèƒ½æ¨¡å—çš„ç±»
   class ResourceManager:
       def __init__(self):
           self.job_handlers = {}
       
       def register_job_handler(self, job_type, handler):
           """é€šè¿‡ä¾èµ–æ³¨å…¥æ³¨å†Œå¤„ç†å™¨"""
           self.job_handlers[job_type] = handler
   ```

### 5. åˆ†æå¯¼å‡ºåŠŸèƒ½é›†æˆé—®é¢˜ ğŸ“Š

**é£é™©ç­‰çº§**: ä¸­é«˜ - å½±å“å…³é”®ä¸šåŠ¡åŠŸèƒ½

#### é—®é¢˜æè¿°
åˆ†æå¯¼å‡ºåŠŸèƒ½ä¸æ‰¹å¤„ç†åŠŸèƒ½çš„é›†æˆå¯èƒ½å¯¼è‡´åŠŸèƒ½å†²çªã€æ€§èƒ½é—®é¢˜æˆ–æ•°æ®ä¸ä¸€è‡´ã€‚

#### å…·ä½“è¡¨ç°
```python
# åˆ†æå¯¼å‡ºé€‚é…å™¨å¯èƒ½å‡ºç°çš„é—®é¢˜
class AnalysisExportAdapter:
    def export_job_analysis(self, job_id, config):
        # é—®é¢˜1ï¼šä½œä¸šçŠ¶æ€ä¸ä¸€è‡´
        job = self.job_manager.get_job(job_id)
        if job.status != JobStatus.COMPLETED:
            # å¦‚ä½•å¤„ç†æœªå®Œæˆçš„ä½œä¸šï¼Ÿ
            pass
        
        # é—®é¢˜2ï¼šæ•°æ®æ ¼å¼è½¬æ¢é”™è¯¯
        core_config = self._convert_config(config, job)  # å¯èƒ½å¤±è´¥
        
        # é—®é¢˜3ï¼šèµ„æºç«äº‰
        # æ‰¹å¤„ç†å’Œåˆ†æå¯¼å‡ºåŒæ—¶è®¿é—®ç›¸åŒæ–‡ä»¶
```

#### é¢„é˜²å’Œè§£å†³æªæ–½

1. **çŠ¶æ€åŒæ­¥æœºåˆ¶**
   ```python
   class AnalysisExportAdapter:
       def export_job_analysis(self, job_id, config):
           job = self.job_manager.get_job(job_id)
           
           # æ£€æŸ¥ä½œä¸šçŠ¶æ€
           if job.status not in [JobStatus.COMPLETED, JobStatus.RUNNING]:
               raise ValueError(f"ä½œä¸š {job_id} çŠ¶æ€ä¸å…è®¸å¯¼å‡ºåˆ†æ: {job.status}")
           
           # ç­‰å¾…ä½œä¸šå®Œæˆï¼ˆå¦‚æœæ­£åœ¨è¿è¡Œï¼‰
           if job.status == JobStatus.RUNNING:
               self._wait_for_job_completion(job_id, timeout=300)
   ```

2. **æ•°æ®æ ¼å¼éªŒè¯**
   ```python
   def _convert_config(self, batch_config, job):
       """å®‰å…¨çš„é…ç½®è½¬æ¢"""
       try:
           core_config = CoreAnalysisConfig()
           core_config.output_directory = batch_config.output_directory
           core_config.analysis_types = self._validate_analysis_types(
               batch_config.analysis_types
           )
           return core_config
       except Exception as e:
           raise ConfigConversionError(f"é…ç½®è½¬æ¢å¤±è´¥: {e}")
   ```

3. **èµ„æºé”å®šæœºåˆ¶**
   ```python
   def export_job_analysis(self, job_id, config):
       with self.resource_manager.acquire_job_lock(job_id):
           # ç¡®ä¿ç‹¬å è®¿é—®ä½œä¸šèµ„æº
           return self._do_export(job_id, config)
   ```

### 6. æµ‹è¯•ç”¨ä¾‹å¤±æ•ˆ ğŸ§ª

**é£é™©ç­‰çº§**: ä¸­ - å½±å“ä»£ç è´¨é‡ä¿è¯

#### é—®é¢˜æè¿°
ç°æœ‰çš„æµ‹è¯•ç”¨ä¾‹ä¸­çš„å¯¼å…¥è¯­å¥å’Œæ¨¡æ‹Ÿå¯¹è±¡è·¯å¾„éƒ½ä¼šå¤±æ•ˆï¼Œå¯¼è‡´æµ‹è¯•æ— æ³•è¿è¡Œã€‚ç‰¹åˆ«æ˜¯æ¶‰åŠåˆ†æå¯¼å‡ºåŠŸèƒ½çš„æµ‹è¯•ã€‚

#### é¢„é˜²å’Œè§£å†³æªæ–½

1. **æ‰¹é‡æ›´æ–°æµ‹è¯•å¯¼å…¥**
   ```python
   # åˆ›å»ºæµ‹è¯•å¯¼å…¥æ›´æ–°è„šæœ¬
   def update_test_imports():
       test_files = glob.glob('tests/**/*.py', recursive=True)
       for test_file in test_files:
           update_imports_in_file(test_file, IMPORT_MAPPING)
   ```

2. **æ›´æ–°æ¨¡æ‹Ÿå¯¹è±¡è·¯å¾„**
   ```python
   # æ—§çš„æµ‹è¯•ä»£ç 
   @patch('app.core.managers.batch_job_manager.BatchJobManager')
   @patch('app.workers.analysis_export_worker.AnalysisExportWorker')
   def test_batch_processing(self, mock_worker, mock_manager):
       pass
   
   # æ–°çš„æµ‹è¯•ä»£ç 
   @patch('app.features.batch_processing.managers.job_manager.JobManager')
   @patch('app.features.batch_processing.analysis.worker.AnalysisExportWorker')
   def test_batch_processing(self, mock_worker, mock_manager):
       pass
   ```

3. **åˆ†æå¯¼å‡ºåŠŸèƒ½æµ‹è¯•æ›´æ–°**
   ```python
   # æ–°å¢åˆ†æå¯¼å‡ºé€‚é…å™¨æµ‹è¯•
   class TestAnalysisExportAdapter:
       def test_export_completed_job(self):
           adapter = AnalysisExportAdapter(mock_core_service, mock_job_manager)
           # æµ‹è¯•å·²å®Œæˆä½œä¸šçš„åˆ†æå¯¼å‡º
           
       def test_export_running_job_waits(self):
           # æµ‹è¯•æ­£åœ¨è¿è¡Œä½œä¸šçš„ç­‰å¾…æœºåˆ¶
           
       def test_config_conversion(self):
           # æµ‹è¯•é…ç½®è½¬æ¢çš„æ­£ç¡®æ€§
   ```

## å®æ–½é˜¶æ®µæ³¨æ„äº‹é¡¹

### é˜¶æ®µ1ï¼šå‡†å¤‡é˜¶æ®µ



2. **ä¾èµ–å…³ç³»åˆ†æ**
   ```python
   # ä½¿ç”¨å·¥å…·åˆ†æç°æœ‰ä¾èµ–å…³ç³»
   import ast
   import os
   
   def analyze_imports(directory):
       """åˆ†æç›®å½•ä¸­æ‰€æœ‰Pythonæ–‡ä»¶çš„å¯¼å…¥å…³ç³»"""
       imports = {}
       for root, dirs, files in os.walk(directory):
           for file in files:
               if file.endswith('.py'):
                   file_path = os.path.join(root, file)
                   imports[file_path] = extract_imports(file_path)
       return imports
   ```

3. **åˆ¶å®šå›æ»šè®¡åˆ’**
   - å®šä¹‰å›æ»šè§¦å‘æ¡ä»¶
   - å‡†å¤‡å›æ»šè„šæœ¬
   - è®¾ç½®æ£€æŸ¥ç‚¹

### é˜¶æ®µ2ï¼šæ‰§è¡Œé˜¶æ®µ

1. **æ¸è¿›å¼è¿ç§»**
   ```python
   # ä¸è¦ä¸€æ¬¡æ€§ç§»åŠ¨æ‰€æœ‰æ–‡ä»¶ï¼Œè€Œæ˜¯åˆ†æ‰¹è¿›è¡Œ
   MIGRATION_BATCHES = [
       ['core/processing'],
       ['core/resources'],
       ['core/tasks'],
       ['features/batch_processing/models'],
       ['features/batch_processing/managers'],
       ['features/batch_processing/analysis'],  # æ–°å¢åˆ†æå¯¼å‡ºåŠŸèƒ½
       ['features/batch_processing/ui']
   ]
   
   for batch in MIGRATION_BATCHES:
       migrate_batch(batch)
       run_basic_tests()
       # ç‰¹åˆ«æµ‹è¯•åˆ†æå¯¼å‡ºåŠŸèƒ½
       if 'analysis' in batch:
           test_analysis_export_integration()
       if tests_failed():
           rollback_batch(batch)
           break
   ```

2. **å®æ—¶éªŒè¯**
   ```python
   def verify_migration_step():
       """æ¯ä¸ªè¿ç§»æ­¥éª¤åçš„éªŒè¯"""
       checks = [
           check_directory_structure,
           check_import_syntax,
           check_basic_functionality,
           run_smoke_tests
       ]
       
       for check in checks:
           if not check():
               return False
       return True
   ```

### é˜¶æ®µ3ï¼šéªŒè¯é˜¶æ®µ

1. **å…¨é¢æµ‹è¯•æ¸…å•**
   - [ ] åº”ç”¨èƒ½æ­£å¸¸å¯åŠ¨
   - [ ] æ‰€æœ‰UIç•Œé¢èƒ½æ­£å¸¸æ˜¾ç¤º
   - [ ] æ‰¹å¤„ç†åŠŸèƒ½å®Œæ•´å·¥ä½œæµç¨‹
   - [ ] åˆ†æå¯¼å‡ºåŠŸèƒ½æ­£å¸¸å·¥ä½œ
   - [ ] æ‰¹å¤„ç†ä¸åˆ†æå¯¼å‡ºé›†æˆåŠŸèƒ½
   - [ ] æ•°æ®ä¿å­˜å’ŒåŠ è½½åŠŸèƒ½
   - [ ] æ€§èƒ½æ²¡æœ‰æ˜æ˜¾é€€åŒ–

2. **è¾¹ç•Œæƒ…å†µæµ‹è¯•**
   ```python
   def test_edge_cases():
       """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
       test_cases = [
           test_empty_project_load,
           test_corrupted_data_handling,
           test_memory_limit_scenarios,
           test_concurrent_operations,
           test_error_recovery,
           test_analysis_export_during_batch_processing,  # æ–°å¢
           test_batch_processing_with_analysis_enabled,   # æ–°å¢
           test_analysis_export_config_validation        # æ–°å¢
       ]
       
       for test in test_cases:
           try:
               test()
               print(f"âœ“ {test.__name__} é€šè¿‡")
           except Exception as e:
               print(f"âœ— {test.__name__} å¤±è´¥: {e}")
   ```

## æ€§èƒ½å’Œç¨³å®šæ€§è€ƒè™‘

### å¯¼å…¥æ€§èƒ½ä¼˜åŒ–

1. **å»¶è¿Ÿå¯¼å…¥**
   ```python
   # å¯¹äºå¤§å‹æ¨¡å—ï¼Œä½¿ç”¨å»¶è¿Ÿå¯¼å…¥
   class BatchProcessingHandler:
       def __init__(self):
           self._heavy_processor = None
       
       @property
       def heavy_processor(self):
           if self._heavy_processor is None:
               from app.core.processing.heavy_processor import HeavyProcessor
               self._heavy_processor = HeavyProcessor()
           return self._heavy_processor
   ```

2. **å¯¼å…¥ç¼“å­˜**
   ```python
   # ç¼“å­˜å¸¸ç”¨çš„å¯¼å…¥
   _import_cache = {}
   
   def cached_import(module_path):
       if module_path not in _import_cache:
           _import_cache[module_path] = importlib.import_module(module_path)
       return _import_cache[module_path]
   ```

### å†…å­˜ç®¡ç†

1. **å¯¹è±¡ç”Ÿå‘½å‘¨æœŸç®¡ç†**
   ```python
   class AppContext:
       def __init__(self):
           self._services = {}
           self._cleanup_handlers = []
       
       def register_cleanup(self, handler):
           self._cleanup_handlers.append(handler)
       
       def cleanup(self):
           for handler in self._cleanup_handlers:
               try:
                   handler()
               except Exception as e:
                   print(f"æ¸…ç†å¤±è´¥: {e}")
   ```

## æ•…éšœæ’é™¤æŒ‡å—

### å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ

1. **ImportError: No module named 'xxx'**
   ```python
   # è§£å†³æ­¥éª¤ï¼š
   # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨äºé¢„æœŸä½ç½®
   # 2. æ£€æŸ¥__init__.pyæ–‡ä»¶æ˜¯å¦å­˜åœ¨
   # 3. æ£€æŸ¥PYTHONPATHè®¾ç½®
   # 4. ä½¿ç”¨ç»å¯¹å¯¼å…¥è€Œéç›¸å¯¹å¯¼å…¥
   ```

2. **AttributeError: module has no attribute 'xxx'**
   ```python
   # å¯èƒ½åŸå› ï¼š
   # 1. ç±»ååœ¨è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿå˜åŒ–
   # 2. __init__.pyä¸­æ²¡æœ‰æ­£ç¡®å¯¼å‡ºç±»
   # 3. å¾ªç¯å¯¼å…¥å¯¼è‡´æ¨¡å—æœªå®Œå…¨åŠ è½½
   ```

3. **Qtä¿¡å·æ§½è¿æ¥å¤±è´¥**
   ```python
   # è°ƒè¯•æ–¹æ³•ï¼š
   def debug_signal_connection(signal, slot):
       try:
           signal.connect(slot)
           print(f"âœ“ ä¿¡å·è¿æ¥æˆåŠŸ: {signal} -> {slot}")
       except Exception as e:
           print(f"âœ— ä¿¡å·è¿æ¥å¤±è´¥: {e}")
           print(f"  ä¿¡å·ç±»å‹: {type(signal)}")
           print(f"  æ§½ç±»å‹: {type(slot)}")
   ```

### è°ƒè¯•å·¥å…·å’ŒæŠ€å·§

1. **å¯¼å…¥è·Ÿè¸ª**
   ```python
   import sys
   
   class ImportTracker:
       def __init__(self):
           self.imports = []
           self.original_import = __builtins__['__import__']
           __builtins__['__import__'] = self.track_import
       
       def track_import(self, name, *args, **kwargs):
           self.imports.append(name)
           return self.original_import(name, *args, **kwargs)
   ```

2. **ä¾èµ–å…³ç³»å¯è§†åŒ–**
   ```python
   def generate_dependency_graph():
       """ç”Ÿæˆæ¨¡å—ä¾èµ–å…³ç³»å›¾"""
       import networkx as nx
       import matplotlib.pyplot as plt
       
       G = nx.DiGraph()
       # æ·»åŠ èŠ‚ç‚¹å’Œè¾¹...
       nx.draw(G, with_labels=True)
       plt.savefig('dependency_graph.png')
   ```

é€šè¿‡éµå¾ªè¿™äº›æ³¨æ„äº‹é¡¹å’Œæœ€ä½³å®è·µï¼Œå¯ä»¥å¤§å¤§é™ä½é‡æ„è¿‡ç¨‹ä¸­çš„é£é™©ï¼Œç¡®ä¿é‡æ„çš„æˆåŠŸå®Œæˆã€‚